{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62ca6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ehr_utils, ehr_models\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396df2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 步骤1：获取训练集和测试集 ===\n",
      "总特征数：96，需要log1p变换的特征数：66\n",
      "训练集样本数：8000，验证集样本数：2000\n",
      "原始训练集大小：(8000, 96)\n",
      "原始测试集大小：(2000, 96)\n",
      "\n",
      "=== 步骤2：准备所有模型 ===\n",
      "将训练以下 10 个模型：\n",
      "  1. AdaBoost\n",
      "  2. DecisionTree\n",
      "  3. GaussianNB\n",
      "  4. GradientBoosting\n",
      "  5. LightGBM\n",
      "  6. LinearDiscriminantAnalysis\n",
      "  7. LogisticRegression\n",
      "  8. MLPClassifier\n",
      "  9. RandomForest\n",
      "  10. XGBoost\n",
      "\n",
      "================================================================================\n",
      "开始训练所有模型...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "正在训练模型 1/10：AdaBoost\n",
      "============================================================\n",
      "模型参数：{'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 0.6856988052045783, 'n_estimators': 200, 'random_state': 42}\n",
      "\n",
      "=== 开始 AdaBoost 五折交叉验证 ===\n",
      "\n",
      "----- Fold 1/5 -----\n",
      "训练集 AUC：0.5869，验证集 AUC：0.4865，过拟合：0.1004\n",
      "\n",
      "----- Fold 2/5 -----\n",
      "训练集 AUC：0.5834，验证集 AUC：0.5239，过拟合：0.0595\n",
      "\n",
      "----- Fold 3/5 -----\n",
      "训练集 AUC：0.5440，验证集 AUC：0.5083，过拟合：0.0358\n",
      "\n",
      "----- Fold 4/5 -----\n",
      "训练集 AUC：0.5954，验证集 AUC：0.5015，过拟合：0.0939\n",
      "\n",
      "----- Fold 5/5 -----\n",
      "训练集 AUC：0.5037，验证集 AUC：0.5010，过拟合：0.0026\n",
      "\n",
      "AdaBoost 五折交叉验证结果汇总：\n",
      "各折验证集 AUC: ['0.4865', '0.5239', '0.5083', '0.5015', '0.5010']\n",
      "平均训练集 AUC: 0.5627 ± 0.0344\n",
      "平均验证集 AUC: 0.5042 ± 0.0121\n",
      "平均过拟合程度：0.0584\n",
      "最佳模型来自第 2 折，验证集 AUC：0.5239\n",
      "最佳模型已保存到：models/AdaBoost_cv_0.5042.pkl\n",
      "✓ AdaBoost 训练完成！用时：22.28 秒\n",
      "\n",
      "============================================================\n",
      "正在训练模型 2/10：DecisionTree\n",
      "============================================================\n",
      "模型参数：{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 20, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}\n",
      "\n",
      "=== 开始 DecisionTree 五折交叉验证 ===\n",
      "\n",
      "----- Fold 1/5 -----\n",
      "训练集 AUC：0.5879，验证集 AUC：0.4542，过拟合：0.1337\n",
      "\n",
      "----- Fold 2/5 -----\n",
      "训练集 AUC：0.6516，验证集 AUC：0.5075，过拟合：0.1441\n",
      "\n",
      "----- Fold 3/5 -----\n",
      "训练集 AUC：0.6458，验证集 AUC：0.5130，过拟合：0.1327\n",
      "\n",
      "----- Fold 4/5 -----\n",
      "训练集 AUC：0.6078，验证集 AUC：0.4857，过拟合：0.1221\n",
      "\n",
      "----- Fold 5/5 -----\n",
      "训练集 AUC：0.6003，验证集 AUC：0.5045，过拟合：0.0958\n",
      "\n",
      "DecisionTree 五折交叉验证结果汇总：\n",
      "各折验证集 AUC: ['0.4542', '0.5075', '0.5130', '0.4857', '0.5045']\n",
      "平均训练集 AUC: 0.6187 ± 0.0254\n",
      "平均验证集 AUC: 0.4930 ± 0.0215\n",
      "平均过拟合程度：0.1257\n",
      "最佳模型来自第 3 折，验证集 AUC：0.5130\n",
      "最佳模型已保存到：models/DecisionTree_cv_0.4930.pkl\n",
      "✓ DecisionTree 训练完成！用时：0.72 秒\n",
      "\n",
      "============================================================\n",
      "正在训练模型 3/10：GaussianNB\n",
      "============================================================\n",
      "模型参数：{'priors': None, 'var_smoothing': 1e-09}\n",
      "\n",
      "=== 开始 GaussianNB 五折交叉验证 ===\n",
      "\n",
      "----- Fold 1/5 -----\n",
      "训练集 AUC：0.5659，验证集 AUC：0.4834，过拟合：0.0825\n",
      "\n",
      "----- Fold 2/5 -----\n",
      "训练集 AUC：0.5707，验证集 AUC：0.4886，过拟合：0.0821\n",
      "\n",
      "----- Fold 3/5 -----\n",
      "训练集 AUC：0.5764，验证集 AUC：0.4686，过拟合：0.1078\n",
      "\n",
      "----- Fold 4/5 -----\n",
      "训练集 AUC：0.5759，验证集 AUC：0.4905，过拟合：0.0854\n",
      "\n",
      "----- Fold 5/5 -----\n",
      "训练集 AUC：0.5665，验证集 AUC：0.5118，过拟合：0.0547\n",
      "\n",
      "GaussianNB 五折交叉验证结果汇总：\n",
      "各折验证集 AUC: ['0.4834', '0.4886', '0.4686', '0.4905', '0.5118']\n",
      "平均训练集 AUC: 0.5711 ± 0.0044\n",
      "平均验证集 AUC: 0.4886 ± 0.0139\n",
      "平均过拟合程度：0.0825\n",
      "最佳模型来自第 5 折，验证集 AUC：0.5118\n",
      "最佳模型已保存到：models/GaussianNB_cv_0.4886.pkl\n",
      "✓ GaussianNB 训练完成！用时：0.21 秒\n",
      "\n",
      "============================================================\n",
      "正在训练模型 4/10：GradientBoosting\n",
      "============================================================\n",
      "模型参数：{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "=== 开始 GradientBoosting 五折交叉验证 ===\n",
      "\n",
      "----- Fold 1/5 -----\n",
      "训练集 AUC：0.8341，验证集 AUC：0.4782，过拟合：0.3559\n",
      "\n",
      "----- Fold 2/5 -----\n",
      "训练集 AUC：0.8501，验证集 AUC：0.5398，过拟合：0.3103\n",
      "\n",
      "----- Fold 3/5 -----\n",
      "训练集 AUC：0.8396，验证集 AUC：0.5043，过拟合：0.3353\n",
      "\n",
      "----- Fold 4/5 -----\n",
      "训练集 AUC：0.8412，验证集 AUC：0.5158，过拟合：0.3254\n",
      "\n",
      "----- Fold 5/5 -----\n",
      "训练集 AUC：0.8372，验证集 AUC：0.5105，过拟合：0.3267\n",
      "\n",
      "GradientBoosting 五折交叉验证结果汇总：\n",
      "各折验证集 AUC: ['0.4782', '0.5398', '0.5043', '0.5158', '0.5105']\n",
      "平均训练集 AUC: 0.8404 ± 0.0054\n",
      "平均验证集 AUC: 0.5097 ± 0.0198\n",
      "平均过拟合程度：0.3307\n",
      "最佳模型来自第 2 折，验证集 AUC：0.5398\n",
      "最佳模型已保存到：models/GradientBoosting_cv_0.5097.pkl\n",
      "✓ GradientBoosting 训练完成！用时：24.93 秒\n",
      "\n",
      "============================================================\n",
      "正在训练模型 5/10：LightGBM\n",
      "============================================================\n",
      "模型参数：{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.01, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 748, 'n_jobs': -1, 'num_leaves': 30, 'objective': None, 'random_state': 42, 'reg_alpha': 0.1, 'reg_lambda': 10.0, 'subsample': 0.6, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'bagging_fraction': 0.7911667142271672, 'bagging_freq': 10, 'feature_fraction': 0.5, 'min_data_in_leaf': 100, 'min_sum_hessian_in_leaf': 10.0}\n",
      "\n",
      "=== 开始 LightGBM 五折交叉验证 ===\n",
      "\n",
      "----- Fold 1/5 -----\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1921, number of negative: 4479\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7213\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523810 -> initscore=0.095310\n",
      "[LightGBM] [Info] Start training from score 0.095310\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "训练集 AUC：0.9963，验证集 AUC：0.4896，过拟合：0.5067\n",
      "\n",
      "----- Fold 2/5 -----\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1921, number of negative: 4479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7219\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523810 -> initscore=0.095310\n",
      "[LightGBM] [Info] Start training from score 0.095310\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "训练集 AUC：0.9972，验证集 AUC：0.5044，过拟合：0.4928\n",
      "\n",
      "----- Fold 3/5 -----\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1921, number of negative: 4479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7211\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523810 -> initscore=0.095310\n",
      "[LightGBM] [Info] Start training from score 0.095310\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "训练集 AUC：0.9964，验证集 AUC：0.4834，过拟合：0.5131\n",
      "\n",
      "----- Fold 4/5 -----\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1921, number of negative: 4479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7224\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523810 -> initscore=0.095310\n",
      "[LightGBM] [Info] Start training from score 0.095310\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "训练集 AUC：0.9953，验证集 AUC：0.5026，过拟合：0.4927\n",
      "\n",
      "----- Fold 5/5 -----\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 1920, number of negative: 4480\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7215\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523810 -> initscore=0.095310\n",
      "[LightGBM] [Info] Start training from score 0.095310\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7911667142271672, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7911667142271672\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "训练集 AUC：0.9974，验证集 AUC：0.5125，过拟合：0.4849\n",
      "\n",
      "LightGBM 五折交叉验证结果汇总：\n",
      "各折验证集 AUC: ['0.4896', '0.5044', '0.4834', '0.5026', '0.5125']\n",
      "平均训练集 AUC: 0.9965 ± 0.0008\n",
      "平均验证集 AUC: 0.4985 ± 0.0105\n",
      "平均过拟合程度：0.4980\n",
      "最佳模型来自第 5 折，验证集 AUC：0.5125\n",
      "最佳模型已保存到：models/LightGBM_cv_0.4985.pkl\n",
      "✓ LightGBM 训练完成！用时：5.49 秒\n",
      "\n",
      "============================================================\n",
      "正在训练模型 6/10：LinearDiscriminantAnalysis\n",
      "============================================================\n",
      "模型参数：{'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0008145222883402799}\n",
      "\n",
      "=== 开始 LinearDiscriminantAnalysis 五折交叉验证 ===\n",
      "\n",
      "----- Fold 1/5 -----\n",
      "训练集 AUC：0.5519，验证集 AUC：0.4967，过拟合：0.0552\n",
      "\n",
      "----- Fold 2/5 -----\n",
      "训练集 AUC：0.5587，验证集 AUC：0.4865，过拟合：0.0722\n",
      "\n",
      "----- Fold 3/5 -----\n",
      "训练集 AUC：0.5636，验证集 AUC：0.4723，过拟合：0.0913\n",
      "\n",
      "----- Fold 4/5 -----\n",
      "训练集 AUC：0.5641，验证集 AUC：0.4939，过拟合：0.0702\n",
      "\n",
      "----- Fold 5/5 -----\n",
      "训练集 AUC：0.5558，验证集 AUC：0.4912，过拟合：0.0645\n",
      "\n",
      "LinearDiscriminantAnalysis 五折交叉验证结果汇总：\n",
      "各折验证集 AUC: ['0.4967', '0.4865', '0.4723', '0.4939', '0.4912']\n",
      "平均训练集 AUC: 0.5588 ± 0.0047\n",
      "平均验证集 AUC: 0.4882 ± 0.0086\n",
      "平均过拟合程度：0.0707\n",
      "最佳模型来自第 1 折，验证集 AUC：0.4967\n",
      "最佳模型已保存到：models/LinearDiscriminantAnalysis_cv_0.4882.pkl\n",
      "✓ LinearDiscriminantAnalysis 训练完成！用时：2.54 秒\n",
      "\n",
      "============================================================\n",
      "正在训练模型 7/10：LogisticRegression\n",
      "============================================================\n",
      "模型参数：{'C': 9.975836024182009, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "=== 开始 LogisticRegression 五折交叉验证 ===\n",
      "\n",
      "----- Fold 1/5 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Cache\\Conda\\envs\\EHR172\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 AUC：0.5662，验证集 AUC：0.4960，过拟合：0.0703\n",
      "\n",
      "----- Fold 2/5 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Cache\\Conda\\envs\\EHR172\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 AUC：0.5702，验证集 AUC：0.4914，过拟合：0.0788\n",
      "\n",
      "----- Fold 3/5 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Cache\\Conda\\envs\\EHR172\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 AUC：0.5753，验证集 AUC：0.4653，过拟合：0.1099\n",
      "\n",
      "----- Fold 4/5 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Cache\\Conda\\envs\\EHR172\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 AUC：0.5740，验证集 AUC：0.4882，过拟合：0.0858\n",
      "\n",
      "----- Fold 5/5 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Cache\\Conda\\envs\\EHR172\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 AUC：0.5640，验证集 AUC：0.5132，过拟合：0.0507\n",
      "\n",
      "LogisticRegression 五折交叉验证结果汇总：\n",
      "各折验证集 AUC: ['0.4960', '0.4914', '0.4653', '0.4882', '0.5132']\n",
      "平均训练集 AUC: 0.5699 ± 0.0043\n",
      "平均验证集 AUC: 0.4908 ± 0.0154\n",
      "平均过拟合程度：0.0791\n",
      "最佳模型来自第 5 折，验证集 AUC：0.5132\n",
      "最佳模型已保存到：models/LogisticRegression_cv_0.4908.pkl\n",
      "✓ LogisticRegression 训练完成！用时：1.27 秒\n",
      "\n",
      "============================================================\n",
      "正在训练模型 8/10：MLPClassifier\n",
      "============================================================\n",
      "模型参数：{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-08, 'hidden_layer_sizes': [200, 50], 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "\n",
      "=== 开始 MLPClassifier 五折交叉验证 ===\n",
      "\n",
      "----- Fold 1/5 -----\n",
      "训练集 AUC：0.5271，验证集 AUC：0.5164，过拟合：0.0106\n",
      "\n",
      "----- Fold 2/5 -----\n",
      "训练集 AUC：0.5379，验证集 AUC：0.4966，过拟合：0.0413\n",
      "\n",
      "----- Fold 3/5 -----\n",
      "训练集 AUC：0.5553，验证集 AUC：0.4687，过拟合：0.0866\n",
      "\n",
      "----- Fold 4/5 -----\n",
      "训练集 AUC：0.5480，验证集 AUC：0.5045，过拟合：0.0434\n",
      "\n",
      "----- Fold 5/5 -----\n",
      "训练集 AUC：0.5232，验证集 AUC：0.5218，过拟合：0.0013\n",
      "\n",
      "MLPClassifier 五折交叉验证结果汇总：\n",
      "各折验证集 AUC: ['0.5164', '0.4966', '0.4687', '0.5045', '0.5218']\n",
      "平均训练集 AUC: 0.5383 ± 0.0122\n",
      "平均验证集 AUC: 0.5016 ± 0.0187\n",
      "平均过拟合程度：0.0367\n",
      "最佳模型来自第 5 折，验证集 AUC：0.5218\n",
      "最佳模型已保存到：models/MLPClassifier_cv_0.5016.pkl\n",
      "✓ MLPClassifier 训练完成！用时：4.17 秒\n",
      "\n",
      "============================================================\n",
      "正在训练模型 9/10：RandomForest\n",
      "============================================================\n",
      "模型参数：{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "=== 开始 RandomForest 五折交叉验证 ===\n",
      "\n",
      "----- Fold 1/5 -----\n",
      "训练集 AUC：0.9996，验证集 AUC：0.4824，过拟合：0.5172\n",
      "\n",
      "----- Fold 2/5 -----\n",
      "训练集 AUC：0.9999，验证集 AUC：0.5187，过拟合：0.4812\n",
      "\n",
      "----- Fold 3/5 -----\n",
      "训练集 AUC：0.9998，验证集 AUC：0.4835，过拟合：0.5163\n",
      "\n",
      "----- Fold 4/5 -----\n",
      "训练集 AUC：0.9998，验证集 AUC：0.4989，过拟合：0.5009\n",
      "\n",
      "----- Fold 5/5 -----\n",
      "训练集 AUC：0.9997，验证集 AUC：0.5143，过拟合：0.4854\n",
      "\n",
      "RandomForest 五折交叉验证结果汇总：\n",
      "各折验证集 AUC: ['0.4824', '0.5187', '0.4835', '0.4989', '0.5143']\n",
      "平均训练集 AUC: 0.9998 ± 0.0001\n",
      "平均验证集 AUC: 0.4996 ± 0.0151\n",
      "平均过拟合程度：0.5002\n",
      "最佳模型来自第 2 折，验证集 AUC：0.5187\n",
      "最佳模型已保存到：models/RandomForest_cv_0.4996.pkl\n",
      "✓ RandomForest 训练完成！用时：22.84 秒\n",
      "\n",
      "============================================================\n",
      "正在训练模型 10/10：XGBoost\n",
      "============================================================\n",
      "模型参数：{'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 1.0, 'device': 'gpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'auc', 'feature_types': None, 'feature_weights': None, 'gamma': 0.0, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.022403069086742198, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 5, 'max_leaves': None, 'min_child_weight': 100, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 589, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': 0.14314863930500873, 'reg_lambda': 100.0, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.7300248552604385, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "\n",
      "=== 开始 XGBoost 五折交叉验证 ===\n",
      "\n",
      "----- Fold 1/5 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Cache\\Conda\\envs\\EHR172\\Lib\\site-packages\\xgboost\\core.py:729: UserWarning: [06:04:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 AUC：0.8396，验证集 AUC：0.4910，过拟合：0.3486\n",
      "\n",
      "----- Fold 2/5 -----\n",
      "训练集 AUC：0.8371，验证集 AUC：0.5022，过拟合：0.3349\n",
      "\n",
      "----- Fold 3/5 -----\n",
      "训练集 AUC：0.8354，验证集 AUC：0.4814，过拟合：0.3539\n",
      "\n",
      "----- Fold 4/5 -----\n",
      "训练集 AUC：0.8279，验证集 AUC：0.4974，过拟合：0.3305\n",
      "\n",
      "----- Fold 5/5 -----\n",
      "训练集 AUC：0.8383，验证集 AUC：0.5137，过拟合：0.3246\n",
      "\n",
      "XGBoost 五折交叉验证结果汇总：\n",
      "各折验证集 AUC: ['0.4910', '0.5022', '0.4814', '0.4974', '0.5137']\n",
      "平均训练集 AUC: 0.8357 ± 0.0041\n",
      "平均验证集 AUC: 0.4972 ± 0.0108\n",
      "平均过拟合程度：0.3385\n",
      "最佳模型来自第 5 折，验证集 AUC：0.5137\n",
      "最佳模型已保存到：models/XGBoost_cv_0.4972.pkl\n",
      "✓ XGBoost 训练完成！用时：6.45 秒\n",
      "\n",
      "================================================================================\n",
      "所有模型训练完成！\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 步骤1：获取训练集和测试集 ===\")\n",
    "X_train, X_test, y_train, y_test = ehr_utils.preprocess_ehr_train_test_data('data_processed/benbu_baseline_cleaned_onehot.csv')\n",
    "print(f\"原始训练集大小：{X_train.shape}\")\n",
    "print(f\"原始测试集大小：{X_test.shape}\")\n",
    "\n",
    "print(\"\\n=== 步骤2：准备所有模型 ===\")\n",
    "# 定义所有要训练的模型\n",
    "all_models = [\n",
    "    'AdaBoost', 'DecisionTree', 'GaussianNB', 'GradientBoosting', 'LightGBM', 'LinearDiscriminantAnalysis', 'LogisticRegression', 'MLPClassifier', 'RandomForest', 'XGBoost'\n",
    "]\n",
    "print(f\"将训练以下 {len(all_models)} 个模型：\")\n",
    "for i, model_name in enumerate(all_models, 1):\n",
    "    print(f\"  {i}. {model_name}\")\n",
    "\n",
    "# 存储所有模型的结果\n",
    "all_models_results = {}\n",
    "total_start_time = time.time()\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"开始训练所有模型...\")\n",
    "print(\"-\" * 80)\n",
    "shutil.rmtree('models', ignore_errors=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "for model_idx, model_name in enumerate(all_models, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"正在训练模型 {model_idx}/{len(all_models)}：{model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    model_start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # 获取模型\n",
    "        model = ehr_models.get_model(model_name)\n",
    "        print(f\"模型参数：{model.get_params()}\")\n",
    "        print(f\"\\n=== 开始 {model_name} 五折交叉验证 ===\")\n",
    "        # 交叉验证设置\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        cv_results = {'train_aucs': [], 'val_aucs': [], 'models': [], 'fold_results': []}\n",
    "\n",
    "        # K折交叉验证\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "            print(f'\\n----- Fold {fold + 1}/{n_splits} -----')\n",
    "            X_fold_train = X_train.iloc[train_idx]\n",
    "            X_fold_val = X_train.iloc[val_idx]\n",
    "            y_fold_train = y_train.iloc[train_idx].values  \n",
    "            y_fold_val = y_train.iloc[val_idx].values  \n",
    "\n",
    "            # 计算样本权重\n",
    "            sample_weights = compute_sample_weight(class_weight='balanced', y=y_fold_train)\n",
    "            pos_mask = (y_fold_train == 1)\n",
    "            sample_weights[pos_mask] *= 1.1\n",
    "\n",
    "            # 每次都重新获取模型\n",
    "            fold_model = ehr_models.get_model(model_name)\n",
    "\n",
    "            if model_name == 'LinearDiscriminantAnalysis':\n",
    "                # LDA 不支持样本权重，使用 SMOTE\n",
    "                smote = SMOTE(random_state=42)\n",
    "                X_train_fold_res, y_train_fold_res = smote.fit_resample(X_fold_train, y_fold_train)  # type: ignore\n",
    "                fold_model.fit(X_train_fold_res, y_train_fold_res)  # type: ignore\n",
    "            else:\n",
    "                fold_model.fit(X_fold_train, y_fold_train, sample_weight=sample_weights)  # type: ignore\n",
    "\n",
    "            # 预测\n",
    "            y_train_proba = np.asarray(fold_model.predict_proba(X_fold_train))[:, 1]\n",
    "            y_val_proba = np.asarray(fold_model.predict_proba(X_fold_val))[:, 1]\n",
    "\n",
    "            # 计算 AUC\n",
    "            train_auc = roc_auc_score(y_fold_train, y_train_proba)\n",
    "            val_auc = roc_auc_score(y_fold_val, y_val_proba)\n",
    "            print(f\"训练集 AUC：{train_auc:.4f}，验证集 AUC：{val_auc:.4f}，过拟合：{train_auc - val_auc:.4f}\")\n",
    "            # 保存结果\n",
    "            cv_results['train_aucs'].append(train_auc)\n",
    "            cv_results['val_aucs'].append(val_auc)\n",
    "            cv_results['models'].append(fold_model)\n",
    "            cv_results['fold_results'].append({'fold': fold, 'train_auc': train_auc, 'val_auc': val_auc, 'train_idx': train_idx, 'val_idx': val_idx})\n",
    "\n",
    "        # 计算平均结果\n",
    "        mean_train_auc = np.mean(cv_results['train_aucs'])\n",
    "        mean_val_auc = np.mean(cv_results['val_aucs'])\n",
    "        std_train_auc = np.std(cv_results['train_aucs'])\n",
    "        std_val_auc = np.std(cv_results['val_aucs'])\n",
    "\n",
    "        print(f\"\\n{model_name} 五折交叉验证结果汇总：\")\n",
    "        print(f\"各折验证集 AUC: {[f'{auc:.4f}' for auc in cv_results['val_aucs']]}\")\n",
    "        print(f\"平均训练集 AUC: {mean_train_auc:.4f} ± {std_train_auc:.4f}\")\n",
    "        print(f\"平均验证集 AUC: {mean_val_auc:.4f} ± {std_val_auc:.4f}\")\n",
    "        print(f\"平均过拟合程度：{mean_train_auc - mean_val_auc:.4f}\")\n",
    "        # 选择最佳模型（验证集 AUC 最高的）\n",
    "        best_fold_idx = np.argmax(cv_results['val_aucs'])\n",
    "        best_model = cv_results['models'][best_fold_idx]\n",
    "        best_val_auc = cv_results['val_aucs'][best_fold_idx]\n",
    "        print(f\"最佳模型来自第 {best_fold_idx+1} 折，验证集 AUC：{best_val_auc:.4f}\")\n",
    "\n",
    "        # 保存最佳模型\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        model_filename = f'models/{model_name}_cv_{mean_val_auc:.4f}.pkl'\n",
    "        with open(model_filename, 'wb') as f:\n",
    "            pickle.dump(best_model, f)\n",
    "        print(f\"最佳模型已保存到：{model_filename}\")\n",
    "\n",
    "        # 计算训练时间\n",
    "        model_end_time = time.time()\n",
    "        model_duration = model_end_time - model_start_time\n",
    "\n",
    "        # 保存模型结果\n",
    "        all_models_results[model_name] = {\n",
    "            'mean_train_auc': mean_train_auc,\n",
    "            'mean_val_auc': mean_val_auc,\n",
    "            'std_train_auc': std_train_auc,\n",
    "            'std_val_auc': std_val_auc,\n",
    "            'best_val_auc': best_val_auc,\n",
    "            'overfitting': mean_train_auc - mean_val_auc,\n",
    "            'training_time': model_duration,\n",
    "            'best_model': best_model,\n",
    "            'cv_results': cv_results\n",
    "        }\n",
    "        print(f\"✓ {model_name} 训练完成！用时：{model_duration:.2f} 秒\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {model_name} 训练失败：{str(e)}\")\n",
    "        all_models_results[model_name] = {'error': str(e), 'training_time': time.time() - model_start_time}\n",
    "\n",
    "# 计算总用时\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"所有模型训练完成！\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EHR172",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
